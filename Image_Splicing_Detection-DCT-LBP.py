# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQTGqZ7JrUOFJj_cDJuzbDrzZjZaKSfe
"""

!kaggle datasets download -d divg07/casia-20-image-tampering-detection-dataset

!unzip /content/casia-20-image-tampering-detection-dataset.zip

from skimage.feature import local_binary_pattern
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.svm import SVC, LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.utils import shuffle
import numpy as np
from progressbar import progressbar
import glob
import cv2

def extract_chromatic_channel(bgr_img):
    # Extract 2 chromatic channes from BGR image
    # Input: BGR Image
    # Output: CrCb channels
    ycrcb_image = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2YCR_CB)
    return ycrcb_image[:, :, 1:] # returning the second and thrid channels (Cr and Cb), ignoring the first channel (Y).

# The block_processing function takes a single-channel image (e.g., Cr or Cb channel), a block size, and a stride. It divides the image into overlapping blocks of the specified size, moving the window across the image with the given stride. The function returns a NumPy array of these blocks. This block processing can be useful for tasks that require analyzing small regions of an image independently, such as image splicing detection, texture analysis, or feature extraction.

def block_processing(cb_image, block_size, stride):
    # Divide image into multiple overlap blocks
    # Input: Cr or Cb channel
    # Output: List of blocks
    height, width, _ = cb_image.shape
    img_blocks = []
    for i in range(0, height - block_size, stride):
        for j in range(0, width - block_size, stride):
            img_blocks.append(cb_image[i: i + block_size, \
                j: j + block_size])
    return np.array(img_blocks)

# The extract_lbp_dct function takes a list of image blocks and extracts a feature vector for each block using Local Binary Pattern (LBP) and Discrete Cosine Transform (DCT). It computes the LBP for the Cr and Cb channels, applies the DCT to these LBP images, calculates the standard deviation of the DCT coefficients across all blocks, and concatenates the resulting features into a single feature vector. This feature vector can be used for further analysis or classification tasks, such as image splicing detection.

def extract_lbp_dct(blocks, n_points = 8, radius = 1):
    # Extract feature vector from given blocks
    # Input: List of blocks response with given image
    # Output: Feature vector of given image
    n_blocks, block_size, _, _ = blocks.shape
    CR_feature = np.zeros((n_blocks, block_size, block_size))
    CB_feature = np.zeros((n_blocks, block_size, block_size))
    for idx, block in enumerate(blocks):
        CR_lbp = local_binary_pattern(block[:, :, 0], n_points, radius)
        CR_lbp = np.float32(CR_lbp)
        CR_feature[idx] = cv2.dct(CR_lbp) # performing discrete cosine transformation
        CB_lbp = local_binary_pattern(block[:, :, 1], n_points, radius)
        CB_lbp = np.float32(CB_lbp)
        CB_feature[idx] = cv2.dct(CB_lbp)
    CR_feature = np.std(CR_feature, axis = 0).flatten()
    CB_feature = np.std(CB_feature, axis = 0).flatten()
    return np.concatenate([CR_feature, CB_feature], axis = 0)

def extract_feature(cb_image, block_size, stride):
    # Extract feature from given CrCb channels
    # Input: CrCb channels
    # Output: Feature vector or given original image
    img_blocks = block_processing(cb_image, block_size, stride)
    feature = extract_lbp_dct(img_blocks)
    return feature

# The read_and_extract_feature function processes a list of images by reading each image, extracting chromatic channels, dividing the image into blocks of specified sizes with specified strides, and extracting features from each block. It combines these features into a single feature vector for each image and returns an array of these feature vectors.

def read_and_extract_feature(list_img, block_sizes, strides):
    # Read and extract feature vector from given list images
    total_img = len(list_img)
    dim = 0
    for i in range(len(block_sizes)):
        dim += block_sizes[i] ** 2
    features = np.zeros((total_img, 2*dim)) # 2 is for Cr and Cb features
    for idx in progressbar(range(len(list_img))):
        im         = list_img[idx]
        bgr_img    = cv2.imread(im)
        cb_image   = extract_chromatic_channel(bgr_img)
        tmp        = 0

        #combinig feature in single feature vector
        for i, bz in enumerate(block_sizes):
            features[idx, tmp: tmp + 2*bz**2] = extract_feature(cb_image, bz, strides[i])
            tmp += 2 * bz ** 2
    return features

def process_dataset(folders_real, folders_fake, block_sizes=[32], strides=[16]):
    # Process CASIA dataset
    # Label: 0 - fake image
    #        1 - real image
    list_real = []
    list_fake = []
    for fdr in folders_real:
        list_real += glob.glob(fdr)
    for fdf in folders_fake:
        list_fake += glob.glob(fdf)
    Y_train = np.zeros((len(list_real) + len(list_fake), ), dtype=np.float32)
    Y_train[:len(list_real)] = 1.0
    X_train = read_and_extract_feature(list_real + list_fake, block_sizes=block_sizes, strides=strides)
    return X_train, Y_train

folder_real = ['CASIA2/Au/*.jpg']
folder_fake = ['CASIA2/Tp/*.jpg', 'CASIA2/Tp/*.tif']

print('Build SVM model ...')
X, Y = process_dataset(folder_real, folder_fake)
X, Y = shuffle(X, Y)

scaler = StandardScaler()
X_train = scaler.fit_transform(X)

clf = LinearSVC(max_iter=10000)  # Increase the number of iterations

import warnings
from sklearn.exceptions import ConvergenceWarning

# Suppress convergence warnings
with warnings.catch_warnings():
    warnings.simplefilter("ignore", category=ConvergenceWarning)
    scores = cross_val_score(clf, X_train, Y, cv=5, scoring='f1_macro')

print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))